# Story 5.7: Auto-Delete Old Photos (Storage Cleanup)

## Status

Approved

## Story

**As a** system,  
**I want** to automatically delete the oldest photos when storage approaches the limit,  
**so that** the app continues to function without paid storage.

## Acceptance Criteria

1. Scheduled job runs daily (or triggered when approaching limit)
2. Checks total storage usage in Cloudflare R2
3. If usage exceeds 80% of 10GB limit, deletes oldest photos
4. Deletes photos by upload date regardless of user
5. Updates spot records to remove deleted photo URLs
6. Logs deletion activity for monitoring
7. No user notification for auto-deletion (documented in privacy policy)

## Tasks / Subtasks

- [ ] **Task 0: Install Dependencies** (Prereq)
  - [ ] Run `npm install node-cron`
  - [ ] Run `npm install -D @types/node-cron`

- [ ] **Task 1: Create Storage Cleanup Job** (AC: 1, 2)
  - [ ] Create `apps/api/src/jobs/storageCleanup.job.ts`
  - [ ] Schedule to run daily at off-peak hours
  - [ ] Check R2 bucket storage usage
  - [ ] Trigger cleanup if > 80% of 10GB (8GB)

- [ ] **Task 2: R2 Storage Usage Check** (AC: 2)
  - [ ] Query R2 for bucket stats
  - [ ] Get total bytes used
  - [ ] Compare against threshold
  - [ ] Return usage percentage

- [ ] **Task 3: Identify Oldest Photos** (AC: 4)
  - [ ] Query spots table ordered by savedAt ASC
  - [ ] Filter for spots with photoUrl
  - [ ] Calculate how many photos to delete
  - [ ] Target: bring usage under 70%

- [ ] **Task 4: Delete Photos and Update Spots** (AC: 4, 5)
  - [ ] Delete photos from R2
  - [ ] Update spot records to set photoUrl = null
  - [ ] Use batch operations for efficiency
  - [ ] Handle partial failures

- [ ] **Task 5: Cleanup Logging** (AC: 6)
  - [ ] Log storage usage before cleanup
  - [ ] Log number of photos deleted
  - [ ] Log any errors
  - [ ] Consider alerting if cleanup runs frequently

- [ ] **Task 6: Job Scheduling** (AC: 1)
  - [ ] Use node-cron or similar
  - [ ] Schedule for 3 AM UTC daily
  - [ ] Add manual trigger endpoint for testing
  - [ ] Document job schedule

- [ ] **Task 7: Testing**
  - [ ] Test storage check calculation
  - [ ] Test photo selection logic
  - [ ] Test spot records updated
  - [ ] Test logging output
  - [ ] Write integration tests

## Dev Notes

### Architecture References

- [architecture/7-data-models.md](../architecture/7-data-models.md)
- [architecture/8-infrastructure.md](../architecture/8-infrastructure.md)

### Dependencies

- Story 2.3 (R2 photo storage)
- PRD constraints (10GB free tier)

### Storage Limits

- **Free tier:** 10GB storage
- **Threshold:** 80% (8GB) triggers cleanup
- **Target:** Reduce to 70% (7GB) after cleanup
- **Photo estimate:** ~500KB avg = ~20,000 photos at 10GB

### Storage Cleanup Job

```typescript
// jobs/storageCleanup.job.ts
import cron from 'node-cron';
import { r2Service } from '@/services/r2.service';
import { spotRepository } from '@/repositories/spot.repository';

const STORAGE_LIMIT_BYTES = 10 * 1024 * 1024 * 1024; // 10GB
const CLEANUP_THRESHOLD = 0.8; // 80%
const TARGET_AFTER_CLEANUP = 0.7; // 70%
const AVG_PHOTO_SIZE = 500 * 1024; // 500KB estimate

export function scheduleStorageCleanup() {
  // Run daily at 3 AM UTC
  cron.schedule('0 3 * * *', async () => {
    console.log('[StorageCleanup] Starting daily cleanup check...');
    await runStorageCleanup();
  });
}

export async function runStorageCleanup(): Promise<void> {
  try {
    // Check current storage usage
    const usage = await r2Service.getBucketUsage();
    const usagePercent = usage / STORAGE_LIMIT_BYTES;

    console.log(
      `[StorageCleanup] Current usage: ${(usagePercent * 100).toFixed(1)}% (${formatBytes(usage)})`
    );

    if (usagePercent < CLEANUP_THRESHOLD) {
      console.log('[StorageCleanup] Storage within limits, no cleanup needed');
      return;
    }

    // Calculate how many bytes to free
    const targetUsage = STORAGE_LIMIT_BYTES * TARGET_AFTER_CLEANUP;
    const bytesToFree = usage - targetUsage;
    const estimatedPhotosToDelete = Math.ceil(bytesToFree / AVG_PHOTO_SIZE);

    console.log(
      `[StorageCleanup] Need to free ${formatBytes(
        bytesToFree
      )}, ~${estimatedPhotosToDelete} photos`
    );

    // Get oldest spots with photos
    const oldestSpots = await spotRepository.findOldestWithPhotos(estimatedPhotosToDelete * 2); // Get extras in case some are small

    if (oldestSpots.length === 0) {
      console.log('[StorageCleanup] No photos to delete');
      return;
    }

    // Delete photos and update spots
    let deletedCount = 0;
    let freedBytes = 0;

    for (const spot of oldestSpots) {
      if (freedBytes >= bytesToFree) break;

      try {
        const photoKey = extractPhotoKey(spot.photoUrl!);
        const photoSize = await r2Service.getObjectSize(photoKey);

        await r2Service.deleteObject(photoKey);
        await spotRepository.clearPhotoUrl(spot.id);

        deletedCount++;
        freedBytes += photoSize || AVG_PHOTO_SIZE;
      } catch (error) {
        console.error(`[StorageCleanup] Failed to delete photo for spot ${spot.id}:`, error);
      }
    }

    console.log(
      `[StorageCleanup] Completed: deleted ${deletedCount} photos, freed ${formatBytes(freedBytes)}`
    );
  } catch (error) {
    console.error('[StorageCleanup] Job failed:', error);
    throw error;
  }
}

function formatBytes(bytes: number): string {
  const gb = bytes / (1024 * 1024 * 1024);
  if (gb >= 1) return `${gb.toFixed(2)}GB`;
  const mb = bytes / (1024 * 1024);
  return `${mb.toFixed(1)}MB`;
}
```

### R2 Service Extensions

```typescript
// services/r2.service.ts
export const r2Service = {
  // ... existing methods ...

  getBucketUsage: async (): Promise<number> => {
    // Cloudflare R2 doesn't have a direct "get usage" API
    // Options:
    // 1. List all objects and sum sizes (expensive)
    // 2. Use Cloudflare Analytics API
    // 3. Track in database (maintain running total)

    // For MVP, use database tracking
    const result = await db
      .select({ total: sql<number>`SUM(photo_size)` })
      .from(spots)
      .where(isNotNull(spots.photoSize));

    return result[0]?.total || 0;
  },

  getObjectSize: async (key: string): Promise<number | null> => {
    try {
      const response = await r2Client.send(
        new HeadObjectCommand({
          Bucket: R2_BUCKET,
          Key: key,
        })
      );
      return response.ContentLength || null;
    } catch {
      return null;
    }
  },
};
```

### Spot Repository Extensions

```typescript
// repositories/spot.repository.ts
findOldestWithPhotos: async (limit: number) => {
  return await db.select()
    .from(spots)
    .where(isNotNull(spots.photoUrl))
    .orderBy(asc(spots.savedAt))
    .limit(limit);
},

clearPhotoUrl: async (spotId: string) => {
  await db.update(spots)
    .set({ photoUrl: null, photoSize: null })
    .where(eq(spots.id, spotId));
},
```

### Schema Update for Photo Tracking

```typescript
// Add to spots schema
photoSize: integer('photo_size').nullable(),  // in bytes
```

### Manual Trigger Endpoint (Admin)

```typescript
// routes/admin/admin.routes.ts
router.post('/cleanup/storage', adminAuthMiddleware, async (req, res) => {
  await runStorageCleanup();
  res.json({ message: 'Storage cleanup triggered' });
});
```

### File Locations

**New Files:**

- `apps/api/src/jobs/storageCleanup.job.ts`
- `apps/api/src/routes/admin/admin.routes.ts` (optional)

**Modified Files:**

- `apps/api/src/services/r2.service.ts` - add usage/size methods
- `apps/api/src/repositories/spot.repository.ts` - add cleanup queries
- `apps/api/src/schema/spots.ts` - add photoSize column
- `apps/api/src/index.ts` - schedule job on startup

### Monitoring

```
[StorageCleanup] Starting daily cleanup check...
[StorageCleanup] Current usage: 82.3% (8.23GB)
[StorageCleanup] Need to free 1.23GB, ~2460 photos
[StorageCleanup] Completed: deleted 2512 photos, freed 1.26GB
```

### Testing Coverage

- Storage cleanup job: 90%
- R2 usage tracking: 85%
- Photo deletion: 95%

## Change Log

| Date       | Version | Description            | Author |
| ---------- | ------- | ---------------------- | ------ |
| 2026-01-15 | 1.0     | Initial story creation | PO     |
